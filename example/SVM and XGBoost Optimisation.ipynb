{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eo_logo.png](eo_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning SVM and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to tune a SVM's and XGBoost hyperparameters using a **genetic algorithm**. The NN will be evaluated on the sonar dataset. \n",
    "\n",
    "The optimisation process includes three main steps:<br>\n",
    "1) Coding the **evaluation function** - taking a dictionar of parameters as argument and returning a scalar <br>\n",
    "2) Defining the **search space**, a list of integer, real or categorical parameters<br>\n",
    "3) Running the **optimisation function**<br>\n",
    "\n",
    "The datasety can be found in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks))\n",
    "\n",
    "General evolution_opt documentation can be found [here](https://eliottkalfon.github.io/evolution_opt/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the main packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evolution_opt.genetic import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preparing the sonar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv('sonar_dataset.txt', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the SVM evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(param_dict):\n",
    "    '''\n",
    "    This function will evaluate an SVM classifier using the parameters of a given individual\n",
    "    '''\n",
    "    # evaluate baseline model with standardized dataset\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('svm', SVC(C=param_dict['C'], kernel=param_dict['kernel'], \n",
    "                                  gamma=param_dict['gamma'], degree=param_dict['degree'])))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "    #Returns the average accuracy across the cross validation splits\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    Integer(1, 1000, 'C', step = 10),\n",
    "    Categorical(['rbf', 'linear', 'poly', 'sigmoid'], 'kernel'),\n",
    "    Real(0.001, 0.1, 'gamma', precision = 3),\n",
    "    Integer(1,5, 'degree')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations: 500\n",
      "Best score: 0.9376811594202898\n",
      "Best parameters: {'C': 721, 'kernel': 'rbf', 'gamma': 0.015, 'degree': 1}\n"
     ]
    }
   ],
   "source": [
    "best_params = optimise(evaluate_svm, search_space,\n",
    "             minimize=False, population_size=10,\n",
    "             n_rounds=500, n_children=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 721, 'kernel': 'rbf', 'gamma': 0.015, 'degree': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the XGBoost Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgboost(param_dict):\n",
    "    '''\n",
    "     This function will evaluate an XGBoost classifier using the parameters of a given individual\n",
    "    '''\n",
    "    # evaluate baseline model with standardized dataset\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('xgb', xgb.XGBClassifier(objective='binary:logistic', \n",
    "                                                learning_rate=param_dict['learning_rate'],\n",
    "                                                gamma=param_dict['gamma'], \n",
    "                                                max_depth=param_dict['max_depth'],\n",
    "                                                min_child_weight=param_dict['min_child_weight'], \n",
    "                                                subsample=param_dict['subsample'], \n",
    "                                                colsample_bytree=param_dict['colsample'])))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "    #Returns the average accuracy across the cross validation splits\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    Real(0, 0.9, 'learning_rate'),\n",
    "    Integer(2, 15, 'max_depth'),\n",
    "    Real(0, 5, 'gamma'),\n",
    "    Integer(2, 15, 'min_child_weight'),\n",
    "    Real(0.1, 1, 'subsample'),\n",
    "    Real(0.1, 1, 'colsample')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations: 500\n",
      "Best score: 0.8898550724637682\n",
      "Best parameters: {'learning_rate': 0.182, 'max_depth': 3, 'gamma': 0.392, 'min_child_weight': 3, 'subsample': 0.71, 'colsample': 0.68}\n"
     ]
    }
   ],
   "source": [
    "best_params = optimise(evaluate_xgboost, search_space,\n",
    "             minimize=False, population_size=10,\n",
    "             n_rounds=500, n_children=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.182,\n",
       " 'max_depth': 3,\n",
       " 'gamma': 0.392,\n",
       " 'min_child_weight': 3,\n",
       " 'subsample': 0.71,\n",
       " 'colsample': 0.68}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
